{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "be4be556e732c48fd93c858856029fbd",
          "grade": false,
          "grade_id": "cell-89fa18eaaf69c47f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-HCyO3GMUslc"
      },
      "source": [
        "\n",
        "## *Data Science Sprint 14*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron (i.e. Neural Network)\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)\n",
        "\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "80b53343211b3ec6d5a7d63295854bf8",
          "grade": false,
          "grade_id": "cell-d282993617980687",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "bdGHqG1BUslg"
      },
      "source": [
        "## Part 0: Import Packages\n",
        "\n",
        "For this notebook, you will need to import: \n",
        "\n",
        "- `numpy`\n",
        "- `pandas`\n",
        "- `matplotlib`\n",
        "- `StandardScaler`\n",
        "- `tensorflow`\n",
        "- `keras`\n",
        "- `Sequential`\n",
        "- `Dense`\n",
        "- `GridSearchCV`\n",
        "- `KerasClassifier`\n",
        "\n",
        "You will also need to install `!pip install mlxtend` if you are working on a notebook. **Be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "84e2be87dc9ad72d512f91665cd5c2c3",
          "grade": false,
          "grade_id": "cell-22a157c6967388c1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YaOVFVGnUslh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "111db249c60793826d6f0ef305781ea4",
          "grade": true,
          "grade_id": "cell-ee3f0bbd9fd79ceb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "k3YIUoLLUsli"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert pd.__package__ == 'pandas'\n",
        "assert GridSearchCV.__module__ == 'sklearn.model_selection._search'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9b2b58b20b3c75b2f8ac786fda7fa46d",
          "grade": false,
          "grade_id": "cell-6adae65226f09553",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JWs66IKsUslj"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## Part 1: Review: \n",
        "### Defining Neural Networks \n",
        "\n",
        "\n",
        "- **Neuron:** An individual node of a neural network. It takes in a combination of inputs and weights, multiplies them together, adds a bias term, and then passes the result through an activation function. The result of this process is what the neuron will pass onto the subsequent layer. Neural Network nodes are modeled after the neurons in the human brain. They have a activation function that decides how much signal to pass onto other neurons. In the human brain there is an electrochemical threshold that decides when and when not to fire. \n",
        "- **Input Layer:** The first layer of nodes in a neural network. This layer receives values from our dataset and combines them with the weights and biases before passing the data to the first hidden layer. \n",
        "- **Hidden Layer:** The middle layers of a neural network that are not the input layer or output layer. These nodes perform the same operations as all others, but are not directly accessible during training. Having multiple hidden layers in a neural network architecture is what determines the designation of \"Deep Learning.\"\n",
        "- **Output Layer:** The final layer of our neural network, the output layer outputs our model's final predictions. For regression problems this is a single node that outputs a continuous value. For binary classification, it is a single node that outputs a probability between 0 & 1, and for multi-class implementations the output layer typically includes a node for each of the classes that we are trying to predict.\n",
        "- **Activation:** Activation functions express how strongly or weakly signal should be passed to the next layer given the weighted sum of the previous input + a bias term. The resulting output is usually referred to as an 'activation'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8vR3CN4Uslj"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## Part 2. Simple Perceptron\n",
        "\n",
        "For this task, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJRY5UITUslk",
        "outputId": "41c25876-a809-469e-f0dc-174ca9d01307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoT10x3rUslk"
      },
      "source": [
        "### 2a. Simple Perceptron\n",
        "Construct a simple perceptron using Keras. \n",
        "\n",
        "Make sure to include the following in your model:\n",
        "- Add `1 dense layer` with a `single neuron` \n",
        "- Use a `sigmoid activation function`\n",
        "- Set `epochs` to 10 \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
        "---\n",
        "* Your model should be called `model1`. \n",
        "\n",
        "* The results of your fit model should be assigned to a variable called `h1`. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "533f2731bf5c6bff190bfb764e02fada",
          "grade": false,
          "grade_id": "cell-427690628f9c900b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "xm2hZcXHUsll",
        "outputId": "a45cd80d-b741-4af4-9088-d80a78fbce21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5733\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5700\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5900\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5933\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.6000\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5967\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5967\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6067\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6875 - accuracy: 0.6133\n"
          ]
        }
      ],
      "source": [
        "# build and fit model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "model1.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "h1 = model1.fit(X,y, epochs=10)\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
          "grade": true,
          "grade_id": "cell-bf2ae566afacde8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "b1FuUrIGUsll"
      },
      "outputs": [],
      "source": [
        "# Visible test\n",
        "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
        "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "95d3ee2935a0de64f2a5a22460520e69",
          "grade": true,
          "grade_id": "cell-a957e14380b2f508",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "D7mhUFXaUslm"
      },
      "outputs": [],
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG1DyYvEUslm"
      },
      "source": [
        "### 2b. Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron model (also known as a neural network). \n",
        "\n",
        "Your neural network `must` have: \n",
        "- `2` Hidden Layers\n",
        "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the `myCallback` function below into your model\n",
        "- Set epochs to `100`\n",
        "- Your model should be called `model2` \n",
        "- Save the results of your fit statement to a variable called `h2`. \n",
        "- Use the version of `crossentropy loss` that is appropriate for this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ad238f5d2d4fce7ec4b2bbeb786faf4e",
          "grade": false,
          "grade_id": "cell-eb88d895e6d9479d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AgxcEdoNUslm"
      },
      "outputs": [],
      "source": [
        "#do not delete or modify\n",
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        # if model reaches 99% accuracy, training is terminated \n",
        "        acc_threshold = 0.99\n",
        "        if(logs.get('accuracy') > acc_threshold):   \n",
        "            self.model.stop_training = True\n",
        "            self.model.callback_used = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "314337f29c8cd7f38224a31687a86b12",
          "grade": false,
          "grade_id": "cell-77523c4c64743f16",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "laFBgI1bUsln"
      },
      "outputs": [],
      "source": [
        "# build and fit model\n",
        "model2 = Sequential([Dense(units=15, activation='relu'),\n",
        "                     Dense(units=15, activation=\"relu\"),\n",
        "                     Dense(units=1, activation=\"sigmoid\")])\n",
        "model2.compile(optimizer=\"adam\",\n",
        "               loss=\"binary_crossentropy\",\n",
        "               metrics='accuracy')\n",
        "# YOUR CODE HERE\n",
        "h2 = model2.fit(X,y , epochs=100, callbacks=myCallback())\n",
        "#raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4a5f575f46f151f97f1cebc19a484bae",
          "grade": true,
          "grade_id": "cell-770612ca24334d8a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zzApK18QUsln"
      },
      "outputs": [],
      "source": [
        "# Visible test\n",
        "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
        "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
        "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
          "grade": true,
          "grade_id": "cell-49b1bf7cce22b5b9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "QLMnrJKdUsln"
      },
      "outputs": [],
      "source": [
        "# Hidden tests - you will see the results when you submit to Canvas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b322042f3d8b515b4c5603946e355b13",
          "grade": false,
          "grade_id": "cell-f3490b86d4b284b0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "AzrFDw-sUsln"
      },
      "source": [
        "### 2c. Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. \n",
        "\n",
        "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "You can install this package using the following statement in the terminal\n",
        "\n",
        "```python\n",
        "pip install mlxtend\n",
        "```\n",
        "\n",
        "Or you can install this package using the following statement in your notebook\n",
        "\n",
        "```python\n",
        "!pip install mlxtend\n",
        "```\n",
        "\n",
        "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "77f6f2a9a5839eeba03aabe273a272d0",
          "grade": false,
          "grade_id": "cell-40d69928751b50a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dAV4Q44yUslo",
        "outputId": "fc7c0d5b-cff7-42f1-880a-c730596bd24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
            "11664/11664 [==============================] - 13s 1ms/step\n",
            "   43/11664 [..............................] - ETA: 13s  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mlxtend/plotting/decision_regions.py:244: MatplotlibDeprecationWarning: Passing unsupported keyword arguments to axis() will raise a TypeError in 3.3.\n",
            "  ax.axis(xmin=xx.min(), xmax=xx.max(), y_min=yy.min(), y_max=yy.max())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11664/11664 [==============================] - 16s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "!pip install mlxtend\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6115e8a53cd304ed19dcead4c4ebcaae",
          "grade": false,
          "grade_id": "cell-302694c508c8da0e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-7K3tgXJUslo"
      },
      "source": [
        "#### Review\n",
        "1) Why does the Perceptron (model1) only achieve about 50% accuracy?\n",
        "\n",
        "A simple perceptron can only learn a linear decision boundary as seen in the visualization above. Since the data points are distributed in a way where only a single class is represented per quadrant, a linear decision boundary can never reach an accuracy much higher than about 50% since each class will be equally represented on either side of that linear decision boundary.\n",
        "\n",
        "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and Y?\n",
        "\n",
        "The additional layers and neurons allow a neural networks to learn non-linear relationships between X and Y. Each layer in a neural net represents an N-dimensional vector space. So by passing data from one layer to another, we are passing a data vector from one vector space to another, each with a different dimensions, often times this will change the geometry of the data points (i.e. their distribution in space) in such a way where a linear separation then becomes possible. This is the same idea behind the Kernel Trick in Support Vector Machines (SVM). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "54d26b93a7851569bb4b1b4800181af4",
          "grade": false,
          "grade_id": "cell-db1863a277e4fd6b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rPAUobVoUslo"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
        "- Train your model and report its baseline accuracy. \n",
        "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
        "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
        "- Report your optimized model's accuracy\n",
        "- Use the Heart Disease Dataset provided (binary classification)\n",
        "- Use an appropriate loss function for a binary classification task\n",
        "- Use an appropriate activation function on the final layer of your network.\n",
        "- Train your model using verbose output for ease of grading.\n",
        "- Use GridSearchCV to hyper-parameters tune your model. \n",
        "    - **Use `n_jobs` = 1**\n",
        "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
        "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "XYRw_evjUslo",
        "outputId": "df3928b8-c4d1-446b-c804-0215575f8b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "62    52    1   3       118   186    0        0      190      0      0.0   \n",
              "159   56    1   1       130   221    0        0      163      0      0.0   \n",
              "19    69    0   3       140   239    0        1      151      0      1.8   \n",
              "123   54    0   2       108   267    0        0      167      0      0.0   \n",
              "296   63    0   0       124   197    0        1      136      1      0.0   \n",
              "\n",
              "     slope  ca  thal  target  \n",
              "62       1   0     1       1  \n",
              "159      2   0     3       1  \n",
              "19       2   2     2       1  \n",
              "123      2   0     2       1  \n",
              "296      1   0     2       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18a44b7f-6a68-471b-b2b8-05226ae46989\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>118</td>\n",
              "      <td>186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>140</td>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>267</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>167</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>197</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18a44b7f-6a68-471b-b2b8-05226ae46989')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18a44b7f-6a68-471b-b2b8-05226ae46989 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18a44b7f-6a68-471b-b2b8-05226ae46989');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# load data\n",
        "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
          "grade": false,
          "grade_id": "cell-85dc40f19f5a1d6b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "AFATFIfpUslp"
      },
      "outputs": [],
      "source": [
        "# Create an input matrix named 'X' store it in a 2D numpy array\n",
        "x = df.drop(columns=['target'])\n",
        "X = np.array(x)\n",
        "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
        "Y = np.array(df[\"target\"])\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "825d4f808810a2a8d6301d7453afe478",
          "grade": true,
          "grade_id": "cell-c17c686c974edc2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4Dq-jFq4Uslp"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
        "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
        "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "475835631ff6a34028443dbf604bd922",
          "grade": false,
          "grade_id": "cell-cfc5517cd0b6fa64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "F4vrgva0Uslp"
      },
      "outputs": [],
      "source": [
        "# Create a function named 'create_model' that returns a complied keras model -  required for KerasClassifier\n",
        "# YOUR CODE HERE\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=20, activation=\"relu\", input_dim=13))\n",
        "    model.add(Dense(units=20, activation=\"relu\"))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer=\"adam\",  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "14fafb133c4cbe053b272ae08156e2ab",
          "grade": true,
          "grade_id": "cell-fac25126eaf1eee4",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HTlRMRzkUslp"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert (create_model().__module__ == 'tensorflow.python.keras.engine.sequential') or (create_model().__module__ == 'keras.engine.sequential'), \"create_model should return a keras model that was created using the Sequential class.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0412c74b7803790452d4914d99995dd2",
          "grade": false,
          "grade_id": "cell-fbc3d0a07230078c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fN8a0Ra1Uslp",
        "outputId": "a8ff2f9d-5517-4466-aaf1-4b669ba871b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-185-c984d22090af>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(create_model)\n"
          ]
        }
      ],
      "source": [
        "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
        "model = KerasClassifier(create_model)\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b9a0fd482352443a412e7fdb13f5bae",
          "grade": true,
          "grade_id": "cell-464e7506993775f2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "r38Vs2i0Uslq"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn' or model.__module__== 'keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
          "grade": false,
          "grade_id": "cell-985c0425f3b1304d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "SxdbIaglUslq"
      },
      "outputs": [],
      "source": [
        "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
        "# Use 2 hyper-parameters with 2 possible values for each \n",
        "param_grid = {\"epochs\":[10, 20],\n",
        "              \"batch_size\": [16, 32]}\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a551fd8278b30c1318c036f6ad43b503",
          "grade": true,
          "grade_id": "cell-c765b5db5489d7a2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DvM4wAbRUslq"
      },
      "outputs": [],
      "source": [
        "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2ea6312f4bc1f42809196b696037dd52",
          "grade": false,
          "grade_id": "cell-7cfb4315eab5031c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8Ivvxl9wUslq",
        "outputId": "f7784b7a-0cff-4790-91c0-a6da766f4109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.0362 - accuracy: 0.4215\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.5174 - accuracy: 0.3554\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2051 - accuracy: 0.4256\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.4298\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.5083\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.5992\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6653\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6570\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6860\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6529\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7377\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.2271 - accuracy: 0.5041\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.6157\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6736\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.5992\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6198\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6860\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6570\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.6860\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7190\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6983\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6066\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 14.4332 - accuracy: 0.5413\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.4649 - accuracy: 0.6157\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.6951 - accuracy: 0.6116\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.2636 - accuracy: 0.5579\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.6240\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9387 - accuracy: 0.5868\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8637 - accuracy: 0.5950\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8310 - accuracy: 0.6074\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8375 - accuracy: 0.6198\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.6529\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7141 - accuracy: 0.6230\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.2661 - accuracy: 0.3251\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.0078 - accuracy: 0.3457\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.1848 - accuracy: 0.3868\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.0387 - accuracy: 0.3827\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.7344 - accuracy: 0.4239\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3906 - accuracy: 0.4650\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1132 - accuracy: 0.4321\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.5391\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9384 - accuracy: 0.5144\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.5679\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.5667\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 46.5719 - accuracy: 0.4527\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.0964 - accuracy: 0.4774\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.5624 - accuracy: 0.5021\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.4560 - accuracy: 0.4527\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.5829 - accuracy: 0.5267\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.2997 - accuracy: 0.5267\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.7682 - accuracy: 0.5556\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.5099 - accuracy: 0.5679\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1279 - accuracy: 0.6008\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9067 - accuracy: 0.6255\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7833\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 60.6302 - accuracy: 0.5372\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 40.0964 - accuracy: 0.5372\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.3468 - accuracy: 0.5372\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.2877 - accuracy: 0.5372\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.7728 - accuracy: 0.5992\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.6157\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6488\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6736\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6446\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6653\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6570\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6529\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6612\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6818\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6860\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6612\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6819 - accuracy: 0.6198\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6364\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.6942\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6488\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7869\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.8300 - accuracy: 0.5248\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4501 - accuracy: 0.5744\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.3160 - accuracy: 0.6033\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1915 - accuracy: 0.6116\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0847 - accuracy: 0.5909\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.6198\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8836 - accuracy: 0.5868\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.6488\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7381 - accuracy: 0.6612\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6942\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7691 - accuracy: 0.6488\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7025\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6860\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7231\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7355\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7603\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7727\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7645\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7603\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7479\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0522 - accuracy: 0.6557\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 10.5833 - accuracy: 0.3884\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 5.2817 - accuracy: 0.3843\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.3154 - accuracy: 0.4298\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.4848 - accuracy: 0.4669\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.5447 - accuracy: 0.5702\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.1743 - accuracy: 0.6405\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8133 - accuracy: 0.7231\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7978 - accuracy: 0.6736\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7875 - accuracy: 0.6653\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7847 - accuracy: 0.6694\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7828 - accuracy: 0.6529\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6901\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6716 - accuracy: 0.6860\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7314\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6777\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7438\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7645\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7603\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7397\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7686\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6557\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 16.5709 - accuracy: 0.5597\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 3.7143 - accuracy: 0.4568\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.6102 - accuracy: 0.5761\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7825 - accuracy: 0.6708\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7184 - accuracy: 0.7037\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.7037\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6749\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6996\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6749\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6996\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6955\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7284\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6955\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7078\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6955\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7654\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7572\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7160\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7572\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7572\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7167\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 17.8990 - accuracy: 0.4774\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 4.4199 - accuracy: 0.6255\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 2.8164 - accuracy: 0.6255\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.9000 - accuracy: 0.6255\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 1.0984 - accuracy: 0.6955\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.6831\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8992 - accuracy: 0.6955\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6872\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8217 - accuracy: 0.7078\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7865 - accuracy: 0.6914\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8142 - accuracy: 0.6749\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.8255 - accuracy: 0.6626\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.8021 - accuracy: 0.6502\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6996\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.7149 - accuracy: 0.6790\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.7160\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.7037\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7284\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7531\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7366\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7768 - accuracy: 0.7167\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.7523 - accuracy: 0.4587\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0801 - accuracy: 0.4669\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3876 - accuracy: 0.4587\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.4298\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8814 - accuracy: 0.5041\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.5579\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6570\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.6860\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7355\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.6983\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7869\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 1s 3ms/step - loss: 45.8977 - accuracy: 0.5413\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 25.6079 - accuracy: 0.5413\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 7.6117 - accuracy: 0.5248\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 6.2162 - accuracy: 0.4463\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.1683 - accuracy: 0.5165\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4265 - accuracy: 0.5620\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4634 - accuracy: 0.5744\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0495 - accuracy: 0.5413\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 1.5763 - accuracy: 0.5124\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4264 - accuracy: 0.4091\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.7279 - accuracy: 0.5082\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 19.7558 - accuracy: 0.5413\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.3306 - accuracy: 0.5455\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7727 - accuracy: 0.4380\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0340 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9564 - accuracy: 0.5372\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2496 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.5248\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8479 - accuracy: 0.5289\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.5702\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.5744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdff54a8d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6839 - accuracy: 0.5902\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 28.9203 - accuracy: 0.4444\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 14.1766 - accuracy: 0.4403\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7585 - accuracy: 0.4568\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.3919 - accuracy: 0.5473\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.3010 - accuracy: 0.5226\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9442 - accuracy: 0.5062\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.4555 - accuracy: 0.5350\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3067 - accuracy: 0.5267\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1298 - accuracy: 0.5432\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0088 - accuracy: 0.5514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdff9e08a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9495 - accuracy: 0.5000\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.4429 - accuracy: 0.3951\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1509 - accuracy: 0.4198\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6113 - accuracy: 0.3128\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3577 - accuracy: 0.3909\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1507 - accuracy: 0.3457\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9551 - accuracy: 0.3663\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9032 - accuracy: 0.4979\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8233 - accuracy: 0.4815\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7353 - accuracy: 0.5350\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6091\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.6333\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2761 - accuracy: 0.5248\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8273 - accuracy: 0.6116\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.5868\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6488\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6570\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6653\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6570\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6736\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6405\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6405\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7190\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6570\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6405\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7637 - accuracy: 0.6116\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6612\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7190\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7107\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6942\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6860\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7025\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.7213\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.5459 - accuracy: 0.5413\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.6693 - accuracy: 0.6074\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.9986 - accuracy: 0.6488\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0718 - accuracy: 0.6612\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.4425 - accuracy: 0.6694\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.2200 - accuracy: 0.6818\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.1253 - accuracy: 0.6942\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.9189 - accuracy: 0.6860\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.7068 - accuracy: 0.7066\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4529 - accuracy: 0.6983\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1547 - accuracy: 0.6942\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9723 - accuracy: 0.6901\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8368 - accuracy: 0.6777\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.6901\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.6983\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.7025\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.7066\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7149\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6860\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.7149\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.6885\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.8778 - accuracy: 0.5289\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.0330 - accuracy: 0.3636\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.0794 - accuracy: 0.4545\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.6397 - accuracy: 0.5331\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3346 - accuracy: 0.5413\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1489 - accuracy: 0.5909\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9224 - accuracy: 0.5950\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8235 - accuracy: 0.5909\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.6116\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6405\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.6612\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6736\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6694\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6653\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6612\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.6653\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6488\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6860\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6777\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7107\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7443 - accuracy: 0.6230\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 5.4474 - accuracy: 0.3745\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 4.1109 - accuracy: 0.3909\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.3090 - accuracy: 0.3539\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8552 - accuracy: 0.3992\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.3872 - accuracy: 0.4321\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.8763 - accuracy: 0.4403\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5627 - accuracy: 0.4691\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.3973 - accuracy: 0.4897\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5597\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1210 - accuracy: 0.5432\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.0786 - accuracy: 0.5350\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1464 - accuracy: 0.5391\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8974 - accuracy: 0.6337\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7827 - accuracy: 0.6255\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.6461\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7164 - accuracy: 0.6420\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.6420\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.6872\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.6420\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6955\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5805 - accuracy: 0.6833\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.5084 - accuracy: 0.3951\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 6.4007 - accuracy: 0.4156\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5957 - accuracy: 0.4156\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 3.7162 - accuracy: 0.3086\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0549 - accuracy: 0.3292\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.8138 - accuracy: 0.3457\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 2.5101 - accuracy: 0.3169\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2627 - accuracy: 0.3457\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9973 - accuracy: 0.3457\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7305 - accuracy: 0.3539\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.5644 - accuracy: 0.3704\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.4312 - accuracy: 0.4156\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.2621 - accuracy: 0.4403\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 1.1464 - accuracy: 0.4486\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0865 - accuracy: 0.4938\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.9475 - accuracy: 0.4691\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.5185\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.5309\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.5556\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.6214\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9547 - accuracy: 0.5833\n",
            "Epoch 1/20\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 10.3577 - accuracy: 0.5479\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 1.8939 - accuracy: 0.4818\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.6733\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6997\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6898\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6997\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6931\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6964\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.6964\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7096\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7162\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7129\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7294\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7195\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6832\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.6997\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7723\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.6997\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7624\n"
          ]
        }
      ],
      "source": [
        "# Create Grid Search object and name it 'gs'\n",
        "gs = GridSearchCV(estimator=model,param_grid=param_grid)\n",
        "grid_result = gs.fit(X,Y, verbose=1)\n",
        "# Run Grid Search \n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1FGbY7eUslq",
        "outputId": "c321f7dc-4da0-49e5-d9a7-3bd3338e7e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.7063387870788574 using {'batch_size': 16, 'epochs': 20}\n",
            "Means: 0.6634426236152648, Stdev: 0.08261935206269604 with: {'batch_size': 16, 'epochs': 10}\n",
            "Means: 0.7063387870788574, Stdev: 0.048625104643575445 with: {'batch_size': 16, 'epochs': 20}\n",
            "Means: 0.6037158489227294, Stdev: 0.10439613558153463 with: {'batch_size': 32, 'epochs': 10}\n",
            "Means: 0.6598906993865967, Stdev: 0.04973440748086611 with: {'batch_size': 32, 'epochs': 20}\n"
          ]
        }
      ],
      "source": [
        "# your grid_result object should be able to run in this code \n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}